{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEOS_PATH_ONBOARD = \"VIS_Onshore/Videos\"\n",
    "OBJECT_ANNOTATIONS_ONBOARD_PATH = \"VIS_Onshore/ObjectGT\"\n",
    "VIDEO_FRAMES_PATH_ONBOARD = 'VIS_Onshore_frames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files_onboard = [join(VIDEOS_PATH_ONBOARD, f) for f in listdir(VIDEOS_PATH_ONBOARD) \n",
    "                       if isfile(join(VIDEOS_PATH_ONBOARD, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files_onboard_dict = {}\n",
    "for f in listdir(VIDEOS_PATH_ONBOARD):\n",
    "    if isfile(join(VIDEOS_PATH_ONBOARD, f)):\n",
    "        video_files_onboard_dict[f.split('.')[0]] = join(VIDEOS_PATH_ONBOARD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_gt_files_onboard_dict = {}\n",
    "for f in listdir(OBJECT_ANNOTATIONS_ONBOARD_PATH):\n",
    "    if isfile(join(OBJECT_ANNOTATIONS_ONBOARD_PATH, f)):\n",
    "        object_gt_files_onboard_dict[f.split('.')[0].replace('_ObjectGT','')] = join(OBJECT_ANNOTATIONS_ONBOARD_PATH, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of onboard videos: ', len(video_files_onboard_dict))\n",
    "print('Number of onboard ground truth files: ', len(object_gt_files_onboard_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files_onboard = []\n",
    "for key in video_files_onboard_dict.keys():\n",
    "    if key not in object_gt_files_onboard_dict:\n",
    "        missing_files_onboard.append(key)\n",
    "        \n",
    "print(\"Unlabelled onbord videos: \", missing_files_onboard)\n",
    "\n",
    "\n",
    "# set whether to remove or not the missing videos from the frames generation later\n",
    "remove_missing_files = True\n",
    "if remove_missing_files:\n",
    "    for key in missing_files_onboard:\n",
    "        del video_files_onboard_dict[key]\n",
    "        \n",
    "    print('Number of onboard videos: ', len(video_files_onboard_dict))\n",
    "    print('Number of onboard ground truth files: ', len(object_gt_files_onboard_dict))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ALL on board videos into images with 1 image per frame\n",
    "for video_key in video_files_onboard_dict:\n",
    "    #video_name = 'MVI_1478_VIS'\n",
    "    vidcap = cv2.VideoCapture(video_files_onboard_dict.get(video_key))\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "      cv2.imwrite(VIDEO_FRAMES_PATH_ONBOARD + video_key + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "      success,image = vidcap.read()\n",
    "      #print('Read a new frame: ', success)\n",
    "      count += 1\n",
    "    print(\"Derived %d frames\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean to determine whether to have all frames in one or separate folders (onshore/onboard/nir)\n",
    "SEPARATE_FOLDERS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './train'\n",
    "TEST_PATH = './test'\n",
    "VIDEO_FRAMES_FOLDER_NAME_ONBOARD = 'VIS_Onshore'\n",
    "\n",
    "\n",
    "if SEPARATE_FOLDERS:\n",
    "    TRAIN_ONBOARD = join(TRAIN_PATH, VIDEO_FRAMES_FOLDER_NAME_ONBOARD)\n",
    "    TEST_ONBOARD = join(TEST_PATH, VIDEO_FRAMES_FOLDER_NAME_ONBOARD)\n",
    "\n",
    "    folder_names = [TRAIN_PATH, TEST_PATH, TRAIN_ONBOARD, TEST_ONBOARD]\n",
    "else:\n",
    "    folder_names = [TRAIN_PATH, TEST_PATH]\n",
    "\n",
    "# first create the folders if they don't exist\n",
    "for folder_name in folder_names:\n",
    "    if not (os.path.isdir(folder_name)):\n",
    "        os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_videos_to_frames(video_dict, paths, frame_space=5, train_test_split=0.7):\n",
    "    \"\"\"\n",
    "    Helper function to convert any video frames into jpg images and split them into training and test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    video_dict : dictionary in the form <video_name>:<video_path>\n",
    "    \n",
    "    paths : tuple of the training and test paths to save the images. If both a set to the same path\n",
    "            then all the generated frames will be place in this (same) directory.\n",
    "            \n",
    "    frame_space : the space between the generated frames. Default is 5.\n",
    "    \n",
    "    train_test_split : the ration to split the frames into train and test datasets. Default is 0.7\n",
    "    \"\"\"\n",
    "    train_path = paths[0]\n",
    "    test_path = paths[1]\n",
    "    for video_key in video_dict:\n",
    "        vidcap = cv2.VideoCapture(video_dict.get(video_key))\n",
    "        \n",
    "        # get total frames of video\n",
    "        total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        frame_count = 0\n",
    "        success = True\n",
    "        while success:\n",
    "            if count % frame_space == 0:\n",
    "                if (count <= train_test_split*total_frames):\n",
    "                    cv2.imwrite(join(train_path, video_key) + \"_frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "                else:\n",
    "                    cv2.imwrite(join(test_path, video_key) + \"_frame%d.jpg\" % count, image)\n",
    "                frame_count += 1\n",
    "            success,image = vidcap.read()\n",
    "            #print('Read a new frame: ', success)\n",
    "            count += 1\n",
    "        print(\"Derived %d frames\" % frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEPARATE_FOLDERS:\n",
    "    convert_videos_to_frames(video_files_onboard_dict, [TRAIN_ONBOARD, TEST_ONBOARD])\n",
    "else:\n",
    "    convert_videos_to_frames(video_files_onboard_dict, [TRAIN_PATH, TEST_PATH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = '0'\n",
    "video_name = 'MVI_0797_VIS_OB'\n",
    "\n",
    "# try to draw image with bounding boxes\n",
    "# load the object ground truth files first\n",
    "        \n",
    "objects_onboard = []\n",
    "with open(\"objects_onboard.txt\") as f:\n",
    "    for line in f: \n",
    "        line = line.strip()\n",
    "        objects_onboard.append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relevant frame information for previous video\n",
    "# and for frame 0\n",
    "frame = '5'\n",
    "relevant_objects = [i for i in objects_onboard if i.startswith(video_name + '_frame' + frame)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bounding boxes for the image\n",
    "im = np.array(Image.open(VIDEO_FRAMES_PATH_ONBOARD + video_name + \"_frame\" + frame +\".jpg\"), dtype=np.uint8)\n",
    "\n",
    "# Create figure and axes\n",
    "fig,ax = plt.subplots(1)\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(im)\n",
    "\n",
    "# for every object in frame crate a rectangle patch\n",
    "for entry in relevant_objects:\n",
    "    data = entry.split(',')\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((float(data[1]),float(data[2])),float(data[3]),float(data[4]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relevant_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
